{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkrIb226FVjb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchvision.models as m\n",
        "import torch.nn as nn\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFfAQN68nVL1"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYqXZs2tFVjd"
      },
      "outputs": [],
      "source": [
        "class ImageDataset:\n",
        "    def __init__(self, type = \"train\", transform=None):\n",
        "        self.transform = transform\n",
        "        if type == \"train\":\n",
        "            self.path1 = \"./lazydata/train/X\"\n",
        "            self.path2 = \"./lazydata/train/Y\"\n",
        "            self.data=os.listdir(self.path1)\n",
        "            self.data=[f for f in self.data if f != \".DS_Store\"]\n",
        "        else:\n",
        "            self.path1 = \"./lazydata/test/X\"\n",
        "            self.path2 = \"./lazydata/train/Y\"\n",
        "            self.data=os.listdir(self.path1)\n",
        "            self.data=[f for f in self.data if f != \".DS_Store\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        path = os.path.join(self.path1, str(idx))\n",
        "        image0 = cv2.imread(os.path.join(path, \"rgb/0.png\"))\n",
        "        image1 = cv2.imread(os.path.join(path, \"rgb/1.png\"))\n",
        "        image2 = cv2.imread(os.path.join(path, \"rgb/2.png\"))\n",
        "        # image0 = image0[20:224, 20:200]\n",
        "        # image1 = image1[60:224, 20:224]\n",
        "        # image2 = image2[30:210, 0:224]\n",
        "\n",
        "        normalize0 = transforms.Normalize(mean=[100.9770, 106.3326, 110.9824], std=[54.0573, 50.7763, 50.9337])\n",
        "        normalize1 = transforms.Normalize(mean=[119.7678, 124.4105, 127.7085], std=[61.7536, 57.5833, 58.3284])\n",
        "        normalize2 = transforms.Normalize(mean=[112.5017, 122.9047, 132.4158], std=[63.1012, 58.5006, 58.6347])\n",
        "\n",
        "        if self.transform:\n",
        "            image0 = self.transform(image0)\n",
        "            image1 = self.transform(image1)\n",
        "            image2 = self.transform(image2)\n",
        "            image0 = normalize0(image0)\n",
        "            image1 = normalize1(image1)\n",
        "            image2 = normalize2(image2)\n",
        "\n",
        "        depth = np.load(os.path.join(path, \"depth.npy\"))/1000\n",
        "        depth[0] = (depth[0]-0.6558)/0.4239 * 300\n",
        "        depth[1] = (depth[1]-0.8711)/0.6199 * 300\n",
        "        depth[2] = (depth[2]-1.2106)/1.1016 * 300\n",
        "        \n",
        "        Y = np.load(os.path.join(self.path2, str(idx)+\".npy\"))*1000\n",
        "        \n",
        "        return (image0, image1, image2, depth), Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAp1nLeRFVjg",
        "outputId": "0f47320b-2cd3-4659-8b7a-937c291726fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3396\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "transformations = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.ColorJitter(contrast=(.7,.8), brightness=0, saturation=0, hue=0),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = ImageDataset(type=\"train\", transform = transformations)\n",
        "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [.8, .2], generator=torch.Generator().manual_seed(42))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "print(len(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2q7nJ-IFVjg"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, optimizer):\n",
        "    model.train()\n",
        "    l = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data=torch.cat((data[0],data[1],data[2],data[3]), 1)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        model = model.to(device)\n",
        "        output = model(data)\n",
        "        mse_loss = nn.MSELoss()\n",
        "        loss = mse_loss(output.float(), target.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        l += loss/149\n",
        "        if batch_idx == 148:\n",
        "          print(\"epoch = {}, {}\".format(epoch,l))\n",
        "          l = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjHgwaK1kBad"
      },
      "outputs": [],
      "source": [
        "def test(model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        data=torch.cat((data[0],data[1],data[2],data[3]), 1)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = torch.nn.MSELoss()\n",
        "        mse = loss(output, target)\n",
        "        correct += mse.item()\n",
        "    accuracy = correct / output.size(0)\n",
        "    print(accuracy)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USrkYgYVFVjh",
        "outputId": "044e25d5-a107-4c07-9ac4-563c10c47f82"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model = m.resnet50(weights=m.ResNet50_Weights.DEFAULT)\n",
        "model.eval()\n",
        "model.float()\n",
        "model.fc = nn.Linear(2048, 12)\n",
        "model.conv1 = nn.Conv2d(12, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "model = model.to(device)\n",
        "# optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(0, 70):\n",
        "    train(epoch, model, optimizer) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-A-UhX6FVji"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_resnet.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7qzuJUuYdv7",
        "outputId": "753940d9-f319-46e9-bf2b-5384083190ff"
      },
      "outputs": [],
      "source": [
        "outfile = 'submission.csv'\n",
        "output_file = open(outfile, 'w')\n",
        "titles = ['ID', 'FINGER_POS_1', 'FINGER_POS_2', 'FINGER_POS_3', 'FINGER_POS_4', 'FINGER_POS_5', 'FINGER_POS_6',\n",
        "         'FINGER_POS_7', 'FINGER_POS_8', 'FINGER_POS_9', 'FINGER_POS_10', 'FINGER_POS_11', 'FINGER_POS_12']\n",
        "preds = []\n",
        "t_data = torch.load('./csci-ua-473-intro-to-machine-learning-fall22/test/test/testX.pt')\n",
        "file_ids = t_data[-1]\n",
        "model.eval()\n",
        "t_dataset = ImageDataset(type=\"test\", transform = transformations)\n",
        "t_loader = torch.utils.data.DataLoader(t_dataset, batch_size=1, shuffle=False)\n",
        "for batch_idx, (data, target) in enumerate(t_loader):\n",
        "      data=torch.cat((data[0],data[1],data[2],data[3]), 1)\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)/1000\n",
        "      preds.append(output[0].cpu().detach().numpy())\n",
        "df = pd.concat([pd.DataFrame(file_ids), pd.DataFrame.from_records(preds)], axis = 1, names = titles)\n",
        "df.columns = titles\n",
        "df.to_csv(outfile, index = False)\n",
        "print(\"Written to csv file {}\".format(outfile))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6 (v3.9.6:db3ff76da1, Jun 28 2021, 11:14:58) \n[Clang 12.0.5 (clang-1205.0.22.9)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
